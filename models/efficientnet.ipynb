{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtCsd1oIgMc3OEiL9dPiiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamAdebisi/Computer-Vision-using-PyTorch/blob/main/models/efficientnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp5CqQwyhSy2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for the training and validation sets\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "GYnMFMUqh6PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "gTP2ibTWh66e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Update the path to the correct location of the zip file\n",
        "zip_file_path = 'Human Action Recognition.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Update extraction path if needed\n",
        "    extraction_path = ''\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Update paths accordingly\n",
        "train_data_path = 'Human Action Recognition/train'\n",
        "test_data_path = 'Human Action Recognition/test'"
      ],
      "metadata": {
        "id": "DLpyO-jOi0RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply the transforms to the train and test data\n",
        "train_data = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
        "test_data = datasets.ImageFolder(root=test_data_path, transform=transform)"
      ],
      "metadata": {
        "id": "le8BhWYmi2GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for training and test sets\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "s5s5f6SXi2f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the pre-trained EfficientNet model\n",
        "efficientnet = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# Freeze all the feature extractor layers\n",
        "for param in efficientnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the classifier part of the model to match the number of classes (5 classes)\n",
        "in_features = efficientnet.classifier[1].in_features\n",
        "efficientnet.classifier[1] = nn.Linear(in_features, 5)\n",
        "\n",
        "# Move the model to the device\n",
        "model = efficientnet.to(device)\n",
        "\n",
        "# Define the loss function and the optimizer (only train the last classification layer)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(efficientnet.classifier[1].parameters(), lr=0.001)\n",
        "\n",
        "# Print the model architecture for verification\n",
        "print(efficientnet)\n"
      ],
      "metadata": {
        "id": "Yb6BybS2i24h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize the lists to store train and test loss for each epoch\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "best_loss = torch.inf\n",
        "patience = 5\n",
        "epochs_since_best = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        if isinstance(outputs, tuple):\n",
        "            outputs = outputs[0]  # For models that return auxiliary outputs\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(train_loss)  # Store the train loss for this epoch\n",
        "    train_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # For models that return auxiliary outputs\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_losses.append(test_loss)  # Store the test loss for this epoch\n",
        "    test_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    # Check for best accuracy and stop if not improved after five more epochs\n",
        "    if test_loss < best_loss:\n",
        "        best_loss = test_loss\n",
        "        epochs_since_best = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # Save the model\n",
        "        print(f'Updated best model with accuracy: {test_accuracy:.2f}%')\n",
        "    else:\n",
        "        epochs_since_best += 1\n",
        "        if epochs_since_best > patience:\n",
        "            print(\"Stopping early: no improvement after five consecutive epochs.\")\n",
        "            break"
      ],
      "metadata": {
        "id": "1p3loRtii3Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the epochs vs training and test losses\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pdm5yY-lrBMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Create label index-to-name map\n",
        "output_label_map = {v: k for k, v in test_data.class_to_idx.items()}\n",
        "\n",
        "# Randomly select 10 indices from the dataset\n",
        "sample_indices = random.sample(range(len(test_data)), 10)\n",
        "\n",
        "# Loop over sampled indices\n",
        "for idx in sample_indices:\n",
        "    # Get full image path using ImageFolder's internal sample list\n",
        "    img_path = test_data.samples[idx][0]  # sample = (image_path, label_index)\n",
        "\n",
        "    # Open the original image (before transform, for visualization)\n",
        "    image_true = Image.open(img_path)\n",
        "\n",
        "    # Transform the image and add a batch dimension\n",
        "    image = transform(image_true).unsqueeze(0).to(device)\n",
        "\n",
        "    # Run the model without computing gradients\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    # Plot the image and prediction\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(image_true)\n",
        "    plt.title(f'Prediction: {output_label_map[predicted_class]}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BK1CI5worGGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}