{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model Using LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarDataset(Dataset):\n",
    "    def __init__(self, root_dir, data, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_df = data\n",
    "        self.transform = transform\n",
    "        self.label_map = self._create_label_map()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data_df.iloc[idx, 1]\n",
    "        label = self.label_map[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _create_label_map(self):\n",
    "        unique_labels = sorted(self.data_df['label'].unique())\n",
    "        label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for data augmentation\n",
    "\n",
    "# Use this for colored images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "# Use this for BnW images\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32, 32)),\n",
    "#     transforms.Grayscale(num_output_channels=1),  # Convert to black and white\n",
    "#     transforms.ToTensor(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the paths \n",
    "\n",
    "path = r'/Users/azeez/Desktop/AI/Personal Projects/GitHub/Computer-Vision-using-PyTorch/Human Action Recognition' \n",
    "folder = 'train' \n",
    "activity = 'cycling' \n",
    "img_name = 'Image_93.jpg' \n",
    "\n",
    "# construct the full image path \n",
    "img_path = os.path.join(path, folder, activity, img_name)\n",
    "\n",
    "# Open and display the image \n",
    "image = Image.open(img_path)\n",
    "image.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385, 131)\n"
     ]
    }
   ],
   "source": [
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir = r'/Users/azeez/Desktop/AI/Personal Projects/GitHub/Computer-Vision-using-PyTorch/Human Action Recognition/train'\n",
    "# train_file = r'C:\\Users\\Deepak\\Downloads\\Computer Vision Resources\\Human Action Recognition\\Modified_Training_set.csv'\n",
    "test_root_dir = r'/Users/azeez/Desktop/AI/Personal Projects/GitHub/Computer-Vision-using-PyTorch/Human Action Recognition/test'\n",
    "# test_file = r'C:\\Users\\Deepak\\Downloads\\Computer Vision Resources\\Human Action Recognition\\Reduced_Testing_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transforms to the train and test data \n",
    "train_data = datasets.ImageFolder(root=train_root_dir, transform=transform )\n",
    "test_data = datasets.ImageFolder(root=test_root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cycling', 'dancing', 'drinking', 'eating', 'sitting']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(train_data.classes)\n",
    "num_classes = len(train_data.classes)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
